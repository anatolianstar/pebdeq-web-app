"""
PEBDEQ Products Module - HIGH PERFORMANCE Background Removal Optimized
=====================================================================

This module has been optimized for HIGH PERFORMANCE background removal:

‚úÖ PERFORMANCE OPTIMIZATIONS:
- Multi-core CPU utilization (uses all available cores)
- GPU auto-detection and acceleration (CUDA support)
- BiRefNet model support for highest quality
- Vectorized numpy operations for faster processing
- No compression optimizations for speed
- Processing time tracking and reporting

‚úÖ FEATURES:
- Advanced REMBG with BiRefNet fallback
- BRIA RMBG model support with transformers
- Intelligent fallback system
- High-performance simple background removal
- Detailed logging and performance metrics

‚úÖ API ENDPOINTS:
- /remove-background - High performance endpoint
- Returns processing time, file sizes, dimensions

Last optimized: 2025-01-24
Version: High_Performance_Optimized
"""

import os
import uuid
import base64
from datetime import datetime
from flask import Blueprint, request, jsonify, current_app, send_file
from app.models.models import Product, Category, Order, User, ContactMessage, BlogPost, VariationType, VariationOption, ProductVariation, SiteSettings, ProductReview
from app import db
import jwt
import os
from functools import wraps
from werkzeug.utils import secure_filename
import uuid
from datetime import datetime
import pandas as pd
from io import BytesIO
import tempfile
from PIL import Image, ImageOps
import numpy as np

# Optional imports for AI features - will gracefully fail if not available
try:
    from rembg import remove
    AI_BACKGROUND_REMOVAL_AVAILABLE = True
except ImportError:
    AI_BACKGROUND_REMOVAL_AVAILABLE = False

try:
    from transformers import pipeline
    import torch
    AI_PIPELINE_AVAILABLE = True
except ImportError:
    AI_PIPELINE_AVAILABLE = False

products_bp = Blueprint('products', __name__)

def admin_required(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        token = request.headers.get('Authorization')
        
        if not token:
            return jsonify({'error': 'Token required'}), 401
        
        try:
            # Remove 'Bearer ' prefix if present
            if token.startswith('Bearer '):
                token = token[7:]
            
            data = jwt.decode(token, os.environ.get('SECRET_KEY') or 'dev-secret-key', algorithms=['HS256'])
            user = User.query.get(data['user_id'])
            
            if not user or not user.is_admin:
                return jsonify({'error': 'Admin access required'}), 403
            
            return f(*args, **kwargs)
        
        except jwt.ExpiredSignatureError:
            return jsonify({'error': 'Token expired'}), 401
        except jwt.InvalidTokenError:
            return jsonify({'error': 'Invalid token'}), 401
    
    return decorated_function

@products_bp.route('/')
def product_list():
    try:
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 12, type=int)
        category_slug = request.args.get('category')
        search = request.args.get('search')
        sort_by = request.args.get('sort', 'newest')  # newest, oldest, price_low, price_high
        min_price = request.args.get('min_price', type=float)
        max_price = request.args.get('max_price', type=float)
        
        query = Product.query.filter_by(is_active=True)
        
        # Filter by category
        if category_slug:
            category = Category.query.filter_by(slug=category_slug).first()
            if category:
                query = query.filter_by(category_id=category.id)
        
        # Search filter
        if search:
            query = query.filter(
                Product.name.ilike(f'%{search}%') | Product.description.ilike(f'%{search}%')
            )
        
        # Price filters
        if min_price is not None:
            query = query.filter(Product.price >= min_price)
        if max_price is not None:
            query = query.filter(Product.price <= max_price)
        
        # Sorting
        if sort_by == 'price_low':
            query = query.order_by(Product.price.asc())
        elif sort_by == 'price_high':
            query = query.order_by(Product.price.desc())
        elif sort_by == 'oldest':
            query = query.order_by(Product.created_at.asc())
        else:  # newest
            query = query.order_by(Product.created_at.desc())
        
        products = query.paginate(
            page=page, per_page=per_page, error_out=False
        )
        
        return jsonify({
            'products': [{
                'id': p.id,
                'name': p.name,
                'slug': p.slug,
                'price': p.price,
                'original_price': p.original_price,
                'images': p.images,
                'category': p.category.name,
                'category_slug': p.category.slug,
                'is_featured': p.is_featured,
                'stock_quantity': p.stock_quantity,
                'has_variations': p.has_variations,
                'variation_type': p.variation_type,
                'variation_name': p.variation_name
            } for p in products.items],
            'pagination': {
                'page': products.page,
                'pages': products.pages,
                'per_page': products.per_page,
                'total': products.total
            }
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@products_bp.route('/<slug>')
def product_detail(slug):
    try:
        product = Product.query.filter_by(slug=slug, is_active=True).first()
        
        if not product:
            return jsonify({'error': 'Product not found'}), 404
        
        # Related products from same category
        related_products = Product.query.filter_by(
            category_id=product.category_id,
            is_active=True
        ).filter(Product.id != product.id).limit(4).all()
        
        return jsonify({
            'product': {
                'id': product.id,
                'name': product.name,
                'slug': product.slug,
                'description': product.description,
                'price': product.price,
                'original_price': product.original_price,
                'images': product.images,
                'video_url': product.video_url,
                'category': product.category.name,
                'category_slug': product.category.slug,
                'stock_quantity': product.stock_quantity,
                'is_featured': product.is_featured,
                'is_active': product.is_active,
                'has_variations': product.has_variations,
                'variation_type': product.variation_type,
                'variation_name': product.variation_name,
                'variation_options': product.variation_options,
                'weight': product.weight,
                'dimensions': product.dimensions,
                'material': product.material,
                'created_at': product.created_at.isoformat(),
                'updated_at': product.updated_at.isoformat()
            },
            'related_products': [{
                'id': p.id,
                'name': p.name,
                'slug': p.slug,
                'price': p.price,
                'images': p.images,
                'category': p.category.name
            } for p in related_products]
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@products_bp.route('/category/<slug>')
def products_by_category(slug):
    try:
        category = Category.query.filter_by(slug=slug, is_active=True).first()
        
        if not category:
            return jsonify({'error': 'Category not found'}), 404
        
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 12, type=int)
        sort_by = request.args.get('sort', 'newest')
        
        query = Product.query.filter_by(category_id=category.id, is_active=True)
        
        # Sorting
        if sort_by == 'price_low':
            query = query.order_by(Product.price.asc())
        elif sort_by == 'price_high':
            query = query.order_by(Product.price.desc())
        elif sort_by == 'oldest':
            query = query.order_by(Product.created_at.asc())
        else:  # newest
            query = query.order_by(Product.created_at.desc())
        
        products = query.paginate(
            page=page, per_page=per_page, error_out=False
        )
        
        return jsonify({
            'category': {
                'id': category.id,
                'name': category.name,
                'slug': category.slug,
                'description': category.description,
                'image_url': category.image_url
            },
            'products': [{
                'id': p.id,
                'name': p.name,
                'slug': p.slug,
                'price': p.price,
                'original_price': p.original_price,
                'images': p.images,
                'stock_quantity': p.stock_quantity,
                'is_featured': p.is_featured
            } for p in products.items],
            'pagination': {
                'page': products.page,
                'pages': products.pages,
                'per_page': products.per_page,
                'total': products.total
            }
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@products_bp.route('/search')
def search_products():
    try:
        q = request.args.get('q', '')
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 12, type=int)
        
        if not q:
            return jsonify({'error': 'Search query is required'}), 400
        
        products = Product.query.filter(
            Product.is_active == True,
            Product.name.ilike(f'%{q}%') | Product.description.ilike(f'%{q}%')
        ).order_by(Product.created_at.desc()).paginate(
            page=page, per_page=per_page, error_out=False
        )
        
        return jsonify({
            'query': q,
            'products': [{
                'id': p.id,
                'name': p.name,
                'slug': p.slug,
                'price': p.price,
                'original_price': p.original_price,
                'images': p.images,
                'category': p.category.name,
                'category_slug': p.category.slug,
                'stock_quantity': p.stock_quantity
            } for p in products.items],
            'pagination': {
                'page': products.page,
                'pages': products.pages,
                'per_page': products.per_page,
                'total': products.total
            }
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500 

def unified_background_removal(image, model_type="auto"):
    """
    üöÄ UNIFIED HIGH PERFORMANCE Background Removal
    
    Single function that handles ALL background removal methods:
    - REMBG with BiRefNet (highest quality)
    - BRIA RMBG with transformers
    - Vectorized simple removal (fastest fallback)
    
    Args:
        image: PIL Image object
        model_type: "auto", "rembg", "bria", or "simple"
    
    Returns:
        PIL Image with background removed (RGBA format)
    """
    print("üöÄ Starting UNIFIED HIGH PERFORMANCE Background Removal...")
    
    # Performance setup - dynamic threading and GPU detection
    import multiprocessing
    import torch
    
    if not torch.cuda.is_available():
        cpu_count = multiprocessing.cpu_count()
        torch.set_num_threads(cpu_count)
        print(f"   üñ•Ô∏è  Using all {cpu_count} CPU cores for maximum performance")
    else:
        print("   üöÄ GPU acceleration available (CUDA)")
    
    # Auto-detect best method if model_type is "auto"
    if model_type == "auto":
        if AI_BACKGROUND_REMOVAL_AVAILABLE:
            model_type = "rembg"  # Will use U2Net (RAM optimized)
            print("   üéØ Auto-selected: REMBG with U2Net FORCED (RAM optimized)")
        elif AI_PIPELINE_AVAILABLE:
            model_type = "bria"
            print("   üéØ Auto-selected: BRIA (transformers available)")
        else:
            model_type = "simple"
            print("   üéØ Auto-selected: Simple (no AI dependencies)")
    
    # Convert to RGBA if needed
    if image.mode != 'RGBA':
        image = image.convert('RGBA')
        print(f"   üì∑ Converted {image.mode} to RGBA format")
    
    print(f"   üìè Processing image: {image.size} pixels")
    
    # Method 1: REMBG with BiRefNet (Highest Quality)
    if model_type == "rembg" and AI_BACKGROUND_REMOVAL_AVAILABLE:
        try:
            print("   üé® Method: REMBG with BiRefNet (highest quality)")
            
            # Convert to bytes for REMBG - FIXED BytesIO handling
            input_buffer = BytesIO()
            image.save(input_buffer, format='PNG', optimize=False)
            input_buffer.seek(0)  # ‚Üê FIX: Reset buffer position!
            input_bytes = input_buffer.getvalue()
            
            # DYNAMIC model selection based on model_type parameter
            from rembg import remove, new_session
            import psutil
            
            # Check available RAM for BiRefNet
            available_ram_gb = psutil.virtual_memory().available / (1024**3)
            print(f"   üíæ Available RAM: {available_ram_gb:.1f} GB")
            
            # Get model preference from request
            requested_model = request.form.get('model_preference', 'auto')
            print(f"   üéØ Requested model: {requested_model}")
            
            if requested_model == 'auto':
                # REMBG Auto - Let rembg choose the best model
                print("   üöÄ Using REMBG Auto Selection (Smart Choice)...")
                output_bytes = remove(input_bytes)  # Default rembg behavior
                print("   ‚úÖ REMBG Auto successful (Smart Selection)")
                
            elif requested_model == 'birefnet' and available_ram_gb >= 2.5:
                                 # BiRefNet (Premium Quality) - Requires 2.5GB+ RAM
                try:
                    print("   üåü Using BiRefNet model (Premium Quality)...")
                    session = new_session('birefnet-general')
                    output_bytes = remove(input_bytes, session=session)
                    print("   ‚úÖ BiRefNet successful (Premium Quality)")
                    
                except Exception as e:
                    print(f"   ‚ö†Ô∏è BiRefNet failed: {e}")
                    print("   üîÑ Fallback to U2Net...")
                    output_bytes = remove(input_bytes)
                    print("   ‚úÖ U2Net fallback successful")
                    
            else:
                # U2Net (Stable Quality) - Always works or BiRefNet fallback
                if requested_model == 'birefnet':
                    print(f"   ‚ö†Ô∏è BiRefNet requested but insufficient RAM ({available_ram_gb:.1f} GB < 2.5 GB)")
                    print("   üîÑ Using U2Net instead (Stable Quality)")
                elif requested_model == 'u2net':
                    print("   üéØ Using U2Net model (Stable Quality)...")
                else:
                    print(f"   ‚ö†Ô∏è Unknown model '{requested_model}', using U2Net fallback...")
                
                output_bytes = remove(input_bytes)
                print("   ‚úÖ U2Net successful (Stable Quality)")
            
            # Convert back to PIL
            result_image = Image.open(BytesIO(output_bytes))
            if result_image.mode != 'RGBA':
                result_image = result_image.convert('RGBA')
            
            print("   üéâ REMBG processing completed successfully")
            return result_image
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è REMBG failed: {str(e)}")
            print("   üîÑ Falling back to next method...")
            model_type = "bria" if AI_PIPELINE_AVAILABLE else "simple"
    
    # Method 2: BRIA RMBG with Transformers
    if model_type == "bria" and AI_PIPELINE_AVAILABLE:
        try:
            print("   ü§ñ Method: BRIA RMBG with Transformers")
            
            from transformers import pipeline
            import torch
            
            # Initialize pipeline
            pipe = pipeline("image-segmentation", model="briaai/RMBG-1.4", trust_remote_code=True)
            
            # Process image
            result = pipe(image)
            
            # Extract mask
            if isinstance(result, list) and len(result) > 0:
                mask_data = result[0]
                mask = mask_data.get('mask', mask_data)
            else:
                mask = result
            
            # Convert mask to numpy
            if hasattr(mask, 'numpy'):
                mask_array = mask.numpy()
            elif isinstance(mask, Image.Image):
                mask_array = np.array(mask)
            else:
                mask_array = np.array(mask)
            
            # Normalize mask
            if mask_array.max() <= 1.0:
                mask_array = (mask_array * 255).astype(np.uint8)
            
            # Apply threshold
            mask_binary = (mask_array > 127).astype(np.uint8) * 255
            
            # Check if mask needs inversion
            if np.sum(mask_binary == 0) > np.sum(mask_binary == 255):
                mask_binary = 255 - mask_binary
            
            # Apply to image
            rgba_array = np.array(image)
            if rgba_array.shape[:2] != mask_binary.shape:
                mask_pil = Image.fromarray(mask_binary, mode='L')
                mask_pil = mask_pil.resize((rgba_array.shape[1], rgba_array.shape[0]), Image.Resampling.LANCZOS)
                mask_binary = np.array(mask_pil)
            
            rgba_array[:, :, 3] = mask_binary
            result_image = Image.fromarray(rgba_array, 'RGBA')
            
            print("   üéâ BRIA RMBG processing completed successfully")
            return result_image
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è BRIA RMBG failed: {str(e)}")
            print("   üîÑ Falling back to simple method...")
            model_type = "simple"
    
    # Method 3: Vectorized Simple Background Removal (Fastest Fallback)
    if model_type == "simple":
        try:
            print("   ‚ö° Method: Vectorized Simple Removal (fastest)")
            
            # Get image data
            data = np.array(image)
            h, w = data.shape[:2]
            
            # Get corner colors for background detection
            corner_colors = [
                data[0, 0],      # top-left
                data[0, w-1],    # top-right
                data[h-1, 0],    # bottom-left
                data[h-1, w-1]   # bottom-right
            ]
            
            # Find most common corner color
            from collections import Counter
            corner_tuples = [tuple(color[:3]) for color in corner_colors]
            bg_color = Counter(corner_tuples).most_common(1)[0][0]
            print(f"   üéØ Detected background color: {bg_color}")
            
            # Vectorized color difference calculation (much faster)
            tolerance = 30
            bg_array = np.array(bg_color)
            rgb_data = data[:, :, :3]
            
            # Calculate Manhattan distance for all pixels at once
            diff = np.sum(np.abs(rgb_data - bg_array), axis=2)
            mask = diff < tolerance
            
            # Apply mask to alpha channel
            data[mask, 3] = 0
            
            transparent_pixels = np.sum(mask)
            total_pixels = h * w
            print(f"   üìä Made {transparent_pixels}/{total_pixels} pixels transparent ({transparent_pixels/total_pixels*100:.1f}%)")
            
            result_image = Image.fromarray(data, 'RGBA')
            print("   üéâ Simple vectorized processing completed successfully")
            return result_image
            
        except Exception as e:
            print(f"   ‚ùå All methods failed: {str(e)}")
            print("   üîÑ Returning original image with warning")
            return image
    
    # This should never be reached, but just in case
    print("   ‚ö†Ô∏è No suitable method found, returning original image")
    return image

# Debug fonksiyonu kaldƒ±rƒ±ldƒ± - artƒ±k unified_background_removal i√ßinde built-in debug var

# Eski ayrƒ± fonksiyonlar kaldƒ±rƒ±ldƒ± - artƒ±k sadece unified_background_removal kullanƒ±lƒ±yor

@products_bp.route('/remove-background', methods=['POST'])
def remove_background():
    """HIGH PERFORMANCE background removal endpoint with optimizations"""
    try:
        print("üöÄ Starting HIGH PERFORMANCE background removal endpoint...")
        from datetime import datetime
        start_time = datetime.now()
        
        # Get image data from request
        if 'image' not in request.files:
            return jsonify({'error': 'No image provided'}), 400
        
        image_file = request.files['image']
        if image_file.filename == '':
            return jsonify({'error': 'No image selected'}), 400
        
        # Get model type from form data (default to rembg for best performance)
        model_type = request.form.get('model_type', 'rembg')
        print(f"   Processing with model: {model_type}")
        
        # Read image data
        image_data = image_file.read()
        print(f"   Image file size: {len(image_data)} bytes")
        
        # Open image with PIL
        input_image = Image.open(BytesIO(image_data))
        print(f"   Image dimensions: {input_image.size}")
        print(f"   Image mode: {input_image.mode}")
        
        # Remove background with UNIFIED HIGH PERFORMANCE processing
        output_image = unified_background_removal(input_image, model_type)
        
        # Calculate processing time
        processing_time = (datetime.now() - start_time).total_seconds()
        print(f"   Background removal completed in {processing_time:.2f} seconds")
        
        # Convert to base64 for preview with high quality PNG
        buffer = BytesIO()
        output_image.save(buffer, format='PNG', compress_level=1, optimize=False)  # No compression/optimization for speed
        buffer.seek(0)
        
        # Create base64 string for preview
        preview_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        output_size = len(buffer.getvalue())
        print(f"   Output image size: {output_size} bytes")
        
        print(f"üéâ HIGH PERFORMANCE background removal completed successfully in {processing_time:.2f}s!")
        
        return jsonify({
            'success': True,
            'preview': f'data:image/png;base64,{preview_base64}',
            'message': f'Background removed successfully using {model_type.upper()} (HIGH PERFORMANCE)',
            'model_used': model_type,
            'version': 'High_Performance_Optimized',
            'processing_time': f'{processing_time:.2f}s',
            'input_size': len(image_data),
            'output_size': output_size,
            'dimensions': f'{input_image.size[0]}x{input_image.size[1]}'
        })
    
    except Exception as e:
        print(f"‚ùå HIGH PERFORMANCE background removal failed: {str(e)}")
        import traceback
        print(f"   Full error details: {traceback.format_exc()}")
        
        return jsonify({
            'error': f'HIGH PERFORMANCE background removal failed: {str(e)}',
            'version': 'High_Performance_Optimized',
            'suggestion': 'Try a different model_type parameter (rembg or bria) or check image format'
        }), 500

@products_bp.route('/save-processed-image', methods=['POST'])
def save_processed_image():
    try:
        data = request.get_json()
        
        if 'image_data' not in data:
            return jsonify({'error': 'No image data provided'}), 400
        
        # Remove data:image/png;base64, prefix
        image_data = data['image_data']
        if image_data.startswith('data:image/png;base64,'):
            image_data = image_data.replace('data:image/png;base64,', '')
        
        # Decode base64
        image_bytes = base64.b64decode(image_data)
        
        # Generate unique filename
        filename = f"{uuid.uuid4().hex}.png"
        
        # Save to uploads/products directory - use correct path one level up from app
        upload_dir = os.path.join(os.path.dirname(current_app.root_path), 'uploads', 'products')
        os.makedirs(upload_dir, exist_ok=True)
        
        filepath = os.path.join(upload_dir, filename)
        
        # Save the image
        with open(filepath, 'wb') as f:
            f.write(image_bytes)
        
        # Return the URL
        image_url = f'/uploads/products/{filename}'
        
        return jsonify({
            'success': True,
            'image_url': image_url,
            'message': 'Image saved successfully'
        })
    
    except Exception as e:
        return jsonify({'error': f'Image save failed: {str(e)}'}), 500

@products_bp.route('/upload-cropped-image', methods=['POST'])
def upload_cropped_image():
    try:
        # Get image data from request
        if 'image' not in request.files:
            return jsonify({'error': 'No image provided'}), 400
        
        image_file = request.files['image']
        if image_file.filename == '':
            return jsonify({'error': 'No image selected'}), 400
        
        # Read image data
        image_data = image_file.read()
        
        # Open image with PIL for processing
        input_image = Image.open(BytesIO(image_data))
        
        # Ensure image is in RGB mode and square
        if input_image.mode != 'RGB':
            input_image = input_image.convert('RGB')
        
        # Resize to higher quality square size (800x800) for better quality
        output_image = input_image.resize((800, 800), Image.Resampling.LANCZOS)
        
        # Generate unique filename
        filename = f"{uuid.uuid4().hex}.jpg"
        
        # Save to uploads/products directory - use correct path one level up from app
        upload_dir = os.path.join(os.path.dirname(current_app.root_path), 'uploads', 'products')
        os.makedirs(upload_dir, exist_ok=True)
        
        filepath = os.path.join(upload_dir, filename)
        
        # Save the image with high quality
        output_image.save(filepath, 'JPEG', quality=95, optimize=True)
        
        # Return the URL
        image_url = f'/uploads/products/{filename}'
        
        return jsonify({
            'success': True,
            'image_url': image_url,
            'message': 'Cropped image saved successfully'
        })
    
    except Exception as e:
        return jsonify({'error': f'Cropped image save failed: {str(e)}'}), 500 

@products_bp.route('/products', methods=['GET'])
@admin_required
def get_products():
    try:
        products = Product.query.order_by(Product.created_at.desc()).all()
        
        return jsonify({
            'products': [{
                'id': p.id,
                'name': p.name,
                'slug': p.slug,
                'description': p.description,
                'price': p.price,
                'original_price': p.original_price,
                'stock_quantity': p.stock_quantity,
                'category': p.category.name,
                'category_id': p.category_id,
                'images': p.images or [],
                'video_url': p.video_url,
                'is_featured': p.is_featured,
                'is_active': p.is_active,
                'has_variations': p.has_variations,
                'variation_type': p.variation_type,
                'variation_name': p.variation_name,
                'variation_options': p.variation_options or []
            } for p in products]
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def filter_empty_variations(variation_options):
    """Bo≈ü varyasyonlarƒ± filtrele"""
    if not variation_options:
        return []
    
    filtered_options = []
    for option in variation_options:
        if isinstance(option, dict) and option.get('name', '').strip():
            filtered_options.append(option)
    
    return filtered_options

@products_bp.route('/products', methods=['POST'])
@admin_required
def create_product():
    try:
        data = request.get_json()
        
        if not data or not all(k in data for k in ('name', 'slug', 'price', 'category_id')):
            return jsonify({'error': 'Missing required fields'}), 400
        
        # Bo≈ü varyasyonlarƒ± filtrele
        variation_options = filter_empty_variations(data.get('variation_options', []))
        
        product = Product(
            name=data['name'],
            slug=data['slug'],
            description=data.get('description', ''),
            price=data['price'],
            original_price=data.get('original_price'),
            stock_quantity=data.get('stock_quantity', 0),
            category_id=data['category_id'],
            images=data.get('images', []),
            video_url=data.get('video_url'),
            is_featured=data.get('is_featured', False),
            is_active=data.get('is_active', True),
            has_variations=data.get('has_variations', False),
            variation_type=data.get('variation_type', ''),
            variation_name=data.get('variation_name', ''),
            variation_options=variation_options,
            weight=data.get('weight', ''),
            dimensions=data.get('dimensions', ''),
            material=data.get('material', '')
        )
        
        db.session.add(product)
        db.session.commit()
        
        return jsonify({'message': 'Product created successfully'}), 201
    
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': str(e)}), 500

@products_bp.route('/products/<int:product_id>', methods=['PUT'])
@admin_required
def update_product(product_id):
    try:
        product = Product.query.get_or_404(product_id)
        data = request.get_json()
        
        # Update fields
        if 'name' in data:
            product.name = data['name']
        if 'description' in data:
            product.description = data['description']
        if 'price' in data:
            product.price = data['price']
        if 'original_price' in data:
            product.original_price = data['original_price']
        if 'stock_quantity' in data:
            product.stock_quantity = data['stock_quantity']
        if 'category_id' in data:
            product.category_id = data['category_id']
        if 'images' in data:
            product.images = data['images']
        if 'video_url' in data:
            product.video_url = data['video_url']

        if 'is_featured' in data:
            product.is_featured = data['is_featured']
        if 'is_active' in data:
            product.is_active = data['is_active']
        if 'has_variations' in data:
            product.has_variations = data['has_variations']
        if 'variation_type' in data:
            product.variation_type = data['variation_type']
        if 'variation_name' in data:
            product.variation_name = data['variation_name']
        if 'variation_options' in data:
            product.variation_options = filter_empty_variations(data['variation_options'])
        if 'weight' in data:
            product.weight = data['weight']
        if 'dimensions' in data:
            product.dimensions = data['dimensions']
        if 'material' in data:
            product.material = data['material']
        
        db.session.commit()
        
        return jsonify({'message': 'Product updated successfully'})
    
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': str(e)}), 500

@products_bp.route('/products/<int:product_id>', methods=['DELETE'])
@admin_required
def delete_product(product_id):
    try:
        product = Product.query.get_or_404(product_id)
        db.session.delete(product)
        db.session.commit()
        
        return jsonify({'message': 'Product deleted successfully'})
    
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': str(e)}), 500

@products_bp.route('/products/export-excel', methods=['GET'])
@admin_required
def export_products_excel():
    """Export all products to Excel file"""
    try:
        products = Product.query.all()
        
        # Create product data for Excel
        product_data = []
        for product in products:
            product_data.append({
                'ID': product.id,
                'Name': product.name,
                'Slug': product.slug,
                'Description': product.description,
                'Price': product.price,
                'Original Price': product.original_price,
                'Stock Quantity': product.stock_quantity,
                'Category ID': product.category_id,
                'Category Name': product.category.name,
                'Images': ', '.join(product.images) if product.images else '',
                'Video URL': product.video_url,
                'Is Featured': product.is_featured,
                'Is Active': product.is_active,
                'Has Variations': product.has_variations,
                'Variation Type': product.variation_type,
                'Variation Name': product.variation_name,
                'Weight': product.weight,
                'Dimensions': product.dimensions,
                'Material': product.material,
                'Created At': product.created_at.strftime('%Y-%m-%d %H:%M:%S') if product.created_at else '',
                'Updated At': product.updated_at.strftime('%Y-%m-%d %H:%M:%S') if product.updated_at else ''
            })
        
        # Create DataFrame
        df = pd.DataFrame(product_data)
        
        # Create Excel file in memory
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Products', index=False)
        
        output.seek(0)
        
        filename = f"products_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@products_bp.route('/products/export-template', methods=['GET'])
@admin_required
def export_products_template():
    """Export empty products template for import"""
    try:
        # Get categories for reference
        categories = Category.query.all()
        
        # Create template data with one example row
        template_data = [{
            'ID': '',  # Empty for new products, fill for updates
            'Name': 'Example Product',
            'Slug': 'example-product',
            'Description': 'This is an example product description',
            'Price': 29.99,
            'Original Price': 39.99,
            'Stock Quantity': 10,
            'Category ID': categories[0].id if categories else 1,
            'Images': '/uploads/products/image1.jpg, /uploads/products/image2.jpg',
            'Video URL': 'https://example.com/video.mp4',
            'Is Featured': False,
            'Is Active': True,
            'Has Variations': False,
            'Variation Type': '',
            'Variation Name': '',
            'Weight': '1 kg',
            'Dimensions': '10x10x5 cm',
            'Material': 'Cotton'
        }]
        
        # Create categories data for reference
        category_data = []
        for cat in categories:
            category_data.append({
                'ID': cat.id,
                'Name': cat.name,
                'Slug': cat.slug
            })
        
        # Create Excel file in memory
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # Products template sheet
            df_template = pd.DataFrame(template_data)
            df_template.to_excel(writer, sheet_name='Products Template', index=False)
            
            # Categories reference sheet
            df_categories = pd.DataFrame(category_data)
            df_categories.to_excel(writer, sheet_name='Categories Reference', index=False)
        
        output.seek(0)
        
        filename = f"products_import_template_{datetime.now().strftime('%Y%m%d')}.xlsx"
        
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@products_bp.route('/products/import-excel', methods=['POST'])
@admin_required
def import_products_excel():
    """Import products from Excel file"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file uploaded'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        if not file.filename.endswith(('.xlsx', '.xls')):
            return jsonify({'error': 'File must be Excel format (.xlsx or .xls)'}), 400
        
        # Try to read Excel file - support both export and template formats
        df = None
        sheet_name = None
        
        try:
            # First try to read as export format (Products sheet)
            df = pd.read_excel(file, sheet_name='Products')
            sheet_name = 'Products'
        except:
            try:
                # Then try template format (Products Template sheet)
                df = pd.read_excel(file, sheet_name='Products Template')
                sheet_name = 'Products Template'
            except:
                # Finally try first sheet
                df = pd.read_excel(file, sheet_name=0)
                sheet_name = 'First Sheet'
        
        if df is None:
            return jsonify({'error': 'Could not read Excel file'}), 400
        
        success_count = 0
        error_count = 0
        errors = []
        updated_count = 0
        
        for index, row in df.iterrows():
            try:
                # Validate required fields
                if pd.isna(row['Name']) or pd.isna(row['Price']):
                    errors.append(f"Row {index + 2}: Name and Price are required")
                    error_count += 1
                    continue
                
                # Check if category exists
                category = Category.query.get(row['Category ID'])
                if not category:
                    errors.append(f"Row {index + 2}: Category ID {row['Category ID']} not found")
                    error_count += 1
                    continue
                
                # Process images
                images = []
                if not pd.isna(row['Images']) and row['Images']:
                    images = [img.strip() for img in str(row['Images']).split(',')]
                
                # Helper function to convert string boolean to actual boolean
                def str_to_bool(value):
                    if pd.isna(value):
                        return False
                    if isinstance(value, bool):
                        return value
                    if isinstance(value, str):
                        return value.upper() in ['TRUE', '1', 'YES', 'Y']
                    return bool(value)
                
                # Helper function to generate unique slug
                def generate_unique_slug(base_slug, product_id=None):
                    slug = base_slug
                    counter = 1
                    while True:
                        # Check if slug exists (excluding current product if updating)
                        query = Product.query.filter_by(slug=slug)
                        if product_id:
                            query = query.filter(Product.id != product_id)
                        
                        if not query.first():
                            return slug
                        
                        slug = f"{base_slug}-{counter}"
                        counter += 1
                
                # Check if this is an update (has ID) or new product
                product_id = None
                if 'ID' in row and not pd.isna(row['ID']):
                    product_id = int(row['ID'])
                    product = Product.query.get(product_id)
                    if product:
                        # Update existing product
                        product.name = str(row['Name'])
                        # Generate unique slug for update
                        base_slug = str(row['Slug']) if not pd.isna(row['Slug']) else str(row['Name']).lower().replace(' ', '-')
                        product.slug = generate_unique_slug(base_slug, product.id)
                        product.description = str(row['Description']) if not pd.isna(row['Description']) else ''
                        product.price = float(row['Price'])
                        product.original_price = float(row['Original Price']) if not pd.isna(row['Original Price']) else None
                        product.stock_quantity = int(row['Stock Quantity']) if not pd.isna(row['Stock Quantity']) else 0
                        product.category_id = int(row['Category ID'])
                        product.images = images
                        product.video_url = str(row['Video URL']) if not pd.isna(row['Video URL']) else None
                        product.is_featured = str_to_bool(row['Is Featured'])
                        product.is_active = str_to_bool(row['Is Active']) if not pd.isna(row['Is Active']) else True
                        product.has_variations = str_to_bool(row['Has Variations'])
                        product.variation_type = str(row['Variation Type']) if not pd.isna(row['Variation Type']) else ''
                        product.variation_name = str(row['Variation Name']) if not pd.isna(row['Variation Name']) else ''
                        product.weight = str(row['Weight']) if not pd.isna(row['Weight']) else ''
                        product.dimensions = str(row['Dimensions']) if not pd.isna(row['Dimensions']) else ''
                        product.material = str(row['Material']) if not pd.isna(row['Material']) else ''
                        
                        updated_count += 1
                        continue
                
                # Create new product
                # Generate unique slug for new product
                base_slug = str(row['Slug']) if not pd.isna(row['Slug']) else str(row['Name']).lower().replace(' ', '-')
                unique_slug = generate_unique_slug(base_slug)
                
                product = Product(
                    name=str(row['Name']),
                    slug=unique_slug,
                    description=str(row['Description']) if not pd.isna(row['Description']) else '',
                    price=float(row['Price']),
                    original_price=float(row['Original Price']) if not pd.isna(row['Original Price']) else None,
                    stock_quantity=int(row['Stock Quantity']) if not pd.isna(row['Stock Quantity']) else 0,
                    category_id=int(row['Category ID']),
                    images=images,
                    video_url=str(row['Video URL']) if not pd.isna(row['Video URL']) else None,
                    is_featured=str_to_bool(row['Is Featured']),
                    is_active=str_to_bool(row['Is Active']) if not pd.isna(row['Is Active']) else True,
                    has_variations=str_to_bool(row['Has Variations']),
                    variation_type=str(row['Variation Type']) if not pd.isna(row['Variation Type']) else '',
                    variation_name=str(row['Variation Name']) if not pd.isna(row['Variation Name']) else '',
                    weight=str(row['Weight']) if not pd.isna(row['Weight']) else '',
                    dimensions=str(row['Dimensions']) if not pd.isna(row['Dimensions']) else '',
                    material=str(row['Material']) if not pd.isna(row['Material']) else ''
                )
                
                db.session.add(product)
                success_count += 1
                
            except Exception as e:
                errors.append(f"Row {index + 2}: {str(e)}")
                error_count += 1
                # Rollback session on error to prevent further issues
                db.session.rollback()
        
        # Commit successful imports
        try:
            if success_count > 0 or updated_count > 0:
                db.session.commit()
        except Exception as e:
            db.session.rollback()
            return jsonify({'error': f'Database commit failed: {str(e)}'}), 500
        
        # Create a more detailed message
        if success_count > 0 and updated_count > 0:
            message = f'‚úÖ Excel import tamamlandƒ±: {success_count} yeni √ºr√ºn eklendi, {updated_count} √ºr√ºn g√ºncellendi'
        elif success_count > 0:
            message = f'‚úÖ Excel import tamamlandƒ±: {success_count} yeni √ºr√ºn eklendi'
        elif updated_count > 0:
            message = f'‚úÖ Excel import tamamlandƒ±: {updated_count} √ºr√ºn g√ºncellendi'
        else:
            message = f'‚ö†Ô∏è Excel import tamamlandƒ± ancak hi√ß √ºr√ºn i≈ülenemedi'
        
        if error_count > 0:
            message += f' ({error_count} hata)'
        
        if sheet_name:
            message += f' - Kaynak: {sheet_name}'
        
        return jsonify({
            'message': message,
            'success_count': success_count,
            'updated_count': updated_count,
            'error_count': error_count,
            'errors': errors[:10]  # Limit to first 10 errors
        })
        
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': str(e)}), 500 

# ============ LIKE ENDPOINTS ============

@products_bp.route('/<int:product_id>/like-status', methods=['GET'])
def get_product_like_status(product_id):
    """Get like status for a product"""
    try:
        from app.models.models import ProductLike
        
        # Get current user if authenticated
        user_id = None
        token = request.headers.get('Authorization')
        if token:
            try:
                if token.startswith('Bearer '):
                    token = token[7:]
                data = jwt.decode(token, os.environ.get('SECRET_KEY') or 'dev-secret-key', algorithms=['HS256'])
                user_id = data.get('user_id')
            except:
                pass
        
        # Get product
        product = Product.query.get_or_404(product_id)
        
        # Get like count
        like_count = ProductLike.query.filter_by(product_id=product_id).count()
        
        # Check if user has liked this product
        is_liked = False
        if user_id:
            is_liked = ProductLike.query.filter_by(product_id=product_id, user_id=user_id).first() is not None
        
        return jsonify({
            'is_liked': is_liked,
            'like_count': like_count
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@products_bp.route('/<int:product_id>/like', methods=['POST'])
def toggle_product_like(product_id):
    """Toggle like status for a product"""
    try:
        from app.models.models import ProductLike
        
        # Get current user
        token = request.headers.get('Authorization')
        if not token:
            return jsonify({'error': 'Authentication required'}), 401
        
        try:
            if token.startswith('Bearer '):
                token = token[7:]
            data = jwt.decode(token, os.environ.get('SECRET_KEY') or 'dev-secret-key', algorithms=['HS256'])
            user_id = data['user_id']
        except:
            return jsonify({'error': 'Invalid token'}), 401
        
        # Get product
        product = Product.query.get_or_404(product_id)
        
        # Check if already liked
        existing_like = ProductLike.query.filter_by(product_id=product_id, user_id=user_id).first()
        
        if existing_like:
            # Remove like
            db.session.delete(existing_like)
            action = 'unliked'
            is_liked = False
        else:
            # Add like
            new_like = ProductLike(product_id=product_id, user_id=user_id)
            db.session.add(new_like)
            action = 'liked'
            is_liked = True
        
        db.session.commit()
        
        # Get updated like count
        like_count = ProductLike.query.filter_by(product_id=product_id).count()
        
        return jsonify({
            'is_liked': is_liked,
            'like_count': like_count,
            'action': action
        })
    
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': str(e)}), 500

# ============ REVIEW ENDPOINTS ============

@products_bp.route('/<int:product_id>/reviews', methods=['GET'])
def get_product_reviews(product_id):
    """Get reviews for a product"""
    try:
        # Get product
        product = Product.query.get_or_404(product_id)
        
        # Get reviews
        reviews = ProductReview.query.filter_by(
            product_id=product_id, 
            is_approved=True
        ).order_by(ProductReview.created_at.desc()).all()
        
        reviews_data = []
        for review in reviews:
            reviews_data.append({
                'id': review.id,
                'rating': review.rating,
                'comment': review.comment,
                'user_name': f"{review.user.first_name} {review.user.last_name}" if review.user else "Anonymous",
                'created_at': review.created_at.isoformat(),
                'updated_at': review.updated_at.isoformat()
            })
        
        return jsonify({
            'reviews': reviews_data,
            'total_reviews': len(reviews_data)
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@products_bp.route('/<int:product_id>/reviews', methods=['POST'])
def submit_product_review(product_id):
    """Submit a review for a product"""
    try:
        # Get current user
        token = request.headers.get('Authorization')
        if not token:
            return jsonify({'error': 'Authentication required'}), 401
        
        try:
            if token.startswith('Bearer '):
                token = token[7:]
            data = jwt.decode(token, os.environ.get('SECRET_KEY') or 'dev-secret-key', algorithms=['HS256'])
            user_id = data['user_id']
        except:
            return jsonify({'error': 'Invalid token'}), 401
        
        # Get product
        product = Product.query.get_or_404(product_id)
        
        # Get request data
        review_data = request.get_json()
        if not review_data:
            return jsonify({'error': 'No review data provided'}), 400
        
        rating = review_data.get('rating')
        comment = review_data.get('comment')
        
        # Validate data
        if not rating or not comment:
            return jsonify({'error': 'Rating and comment are required'}), 400
        
        if not isinstance(rating, int) or rating < 1 or rating > 5:
            return jsonify({'error': 'Rating must be between 1 and 5'}), 400
        
        if len(comment.strip()) < 10:
            return jsonify({'error': 'Comment must be at least 10 characters long'}), 400
        
        # Check if user already reviewed this product
        existing_review = ProductReview.query.filter_by(
            product_id=product_id, 
            user_id=user_id
        ).first()
        
        if existing_review:
            return jsonify({'error': 'You have already reviewed this product'}), 400
        
        # Create new review
        review = ProductReview(
            product_id=product_id,
            user_id=user_id,
            rating=rating,
            comment=comment.strip(),
            is_approved=True  # Auto-approve for now
        )
        
        db.session.add(review)
        db.session.commit()
        
        return jsonify({
            'message': 'Review submitted successfully',
            'review': {
                'id': review.id,
                'rating': review.rating,
                'comment': review.comment,
                'created_at': review.created_at.isoformat()
            }
        }), 201
    
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': str(e)}), 500 